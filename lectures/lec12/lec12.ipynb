{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rc('figure', dpi=100, figsize=(10, 5))\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 12 â€“ Missing Values, Continued\n",
    "\n",
    "## DSC 80, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Discussion 4 is due for extra credit **tomorrow at 11:59PM**.\n",
    "- Lab 4 is due on **Monday, April 25th at 11:59PM**.\n",
    "    - No hidden tests, just for this lab! Public notebook tests = Gradescope tests.\n",
    "    - Check [here](https://campuswire.com/c/G325FA25B/feed/767) for clarifications.\n",
    "- Project 2 is due on **Saturday, April 30th at 11:59PM**.\n",
    "- The Midterm Exam is **in-class, in-person on Wednesday, April 27th.** More details to come over the weekend.\n",
    "    - It will cover Lectures **1-12**, Labs 1-4, Projects 1-2, and Discussions 1-4.\n",
    "    - Unless you email Suraj beforehand, you **must take the exam during the section you are enrolled in**.\n",
    "    - A single, two-sided cheat sheet will be allowed.\n",
    "    - See the [Resources](https://dsc80.com/resources/) tab for past exams, and expect a Spring 2021 Midterm review video from Murali this weekend.\n",
    "- ðŸš¨ If 80% of the class fills out the **[Mid-Quarter Survey](https://docs.google.com/forms/d/e/1FAIpQLSd9k90fGqPKDRAnHjFBEx5kak_VtvYN5Fq5uPv9jyqrryaKeA/viewform)**, then everyone will receive an extra point on the Midterm Exam. ðŸš¨\n",
    "    - As of lecture, we're currently under 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Review: missingness mechanisms.\n",
    "- Identifying missingness mechanisms using data.\n",
    "- The Kolmogorov-Smirnov test statistic.\n",
    "\n",
    "Remember: today's lecture **is in scope** for the Midterm Exam!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missingness mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review: missingness mechanisms\n",
    "\n",
    "- **Missing by design (MD):** Whether or not a value is missing depends entirely on the data in other columns. In other words, if we can always predict if a value will be missing given the other columns, the data is MD.\n",
    "- **Not missing at random (NMAR, also called NI):** The chance that a value is missing **depends on the actual missing value**!\n",
    "- **Missing at random (MAR):** The chance that a value is missing **depends on other columns**, but **not** the actual missing value itself.\n",
    "- **Missing completely at random (MCAR):** The chance that a value is missing is **completely independent** of other columns and the actual missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Flowchart\n",
    "\n",
    "A good strategy is to assess missingness in the following order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing by design (MD)</b></center>\n",
    "<center><i>Can I determine the missing value exactly by looking at the other columns? ðŸ¤”</i></center>\n",
    "$$\\downarrow$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Not missing at random (NMAR)</b></center>\n",
    "<center><i>Is there a good reason why the missingness depends on the values themselves? ðŸ¤”</i></center>\n",
    "$$\\downarrow$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing at random (MAR)</b></center>\n",
    "<center><i>Do other columns tell me anything about the likelihood that a value is missing? ðŸ¤”</i></center>\n",
    "$$\\downarrow$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Missing completely at random (MCAR)</b></center>\n",
    "<center><i>The missingness must not depend on other columns or the values themselves. ðŸ˜„</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "In each of the following examples, decide whether the missing data are MD, NMAR, MAR, or MCAR:\n",
    "\n",
    "* A table for a medical study has columns for `'gender'` and `'age'`. **`'age'` has missing values**.\n",
    "* Measurements from the Hubble Space Telescope are **dropped during transmission**.\n",
    "* A table has a single column, `'self-reported education level'`, **which contains missing values**.\n",
    "* A table of grades contains three columns, `'Version 1'`, `'Version 2'`, and `'Version 3'`. **$\\frac{2}{3}$ of the entries in the table are `NaN`.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why do we care again?\n",
    "\n",
    "- If a dataset contains missing values, it is likely not an accurate picture of the data generating process.\n",
    "- By identifying missingness mechanisms, we can best **fill in** missing values, to gain a better understanding of the DGP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formal definition: MCAR\n",
    "\n",
    "Suppose we have:\n",
    "- A dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- A parameter $\\psi$ that represents all relevant information that is not part of the dataset.\n",
    "\n",
    "Data is **missing completely at random** (MCAR) if \n",
    "\n",
    "$$\\text{P}(\\text{data is present} \\: | \\: Y_{obs}, Y_{mis}, \\psi) = \\text{P}(\\text{data is present} \\: | \\: \\psi)$$\n",
    "\n",
    "That is, adding information about the dataset doesn't change the likelihood data is missing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formal definition: MAR\n",
    "\n",
    "Suppose we have:\n",
    "- A dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- A parameter $\\psi$ that represents all relevant information that is not part of the dataset.\n",
    "\n",
    "Data is **missing at random** (MCAR) if \n",
    "\n",
    "$$\\text{P}(\\text{data is present} \\: | \\: Y_{obs}, Y_{mis}, \\psi) = \\text{P}(\\text{data is present} \\: | \\: Y_{obs},  \\psi)$$\n",
    "\n",
    "That is, MAR data is **actually MCAR**, **conditional** on $Y_{obs}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formal definition: NMAR\n",
    "\n",
    "Suppose we have:\n",
    "- A dataset $Y$ with observed values $Y_{obs}$ and missing values $Y_{mis}$.\n",
    "- A parameter $\\psi$ that represents all relevant information that is not part of the dataset.\n",
    "\n",
    "\n",
    "Data is **not missing at random** (NMAR) if  \n",
    "\n",
    "$$\\text{P}(\\text{data is present} \\: | \\: Y_{obs}, Y_{mis}, \\psi)$$\n",
    "\n",
    "cannot be simplified. That is, in NMAR data, **missingness is dependent on the missing value** itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assessing missingness through data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing missingness through data\n",
    "\n",
    "- Suppose I believe that the missingness mechanism of a column is NMAR, MAR, or MCAR.\n",
    "    - I've ruled out missing by design (a good first step).\n",
    "- Can I determine the missingness mechanism by looking at the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing NMAR\n",
    "\n",
    "- We can't determine if data is NMAR just by looking at the data, as whether or not data is NMAR depends on the **unobserved data**.\n",
    "- To establish if data is NMAR, we must:\n",
    "    - **reason about the data generating process**, or\n",
    "    - collect more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Example:** Consider a dataset of survey data of students' self-reported happiness. The data contains PIDs and happiness scores; nothing else. Some happiness scores are missing. **Are happiness scores likely NMAR?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer:** Yes. For them to be MAR, there need to be other relevant columns in the dataset, which there are not. For it to be MCAR, we'd need some reason to believe that scores were dropped at random. Without any other information, we must assume that students with lower happiness scores didn't fill out the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing MAR\n",
    "\n",
    "- Data is MAR if the missingness only depends on **observed** data.\n",
    "- After reasoning about the data generating process, if you establish that data is not NMAR, then it must be either MAR or MCAR.\n",
    "- The more columns we have in our dataset, the \"weaker the NMAR effect\" is.\n",
    "    - Adding more columns -> controlling for more variables -> moving from NMAR to MAR.\n",
    "    - **Example:** With no other columns, income in a census is NMAR. But once we look at location, education, and occupation, incomes are closer to being MAR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing MCAR\n",
    "\n",
    "- For data to be MCAR, the chance that values are missing should not depend on any other column or the values themselves.\n",
    "- **Example:** Consider a dataset of phones, in which we store the screen size and price of each phone. **Some prices are missing.**\n",
    "\n",
    "| Phone | Screen Size | Price |\n",
    "| --- | --- | --- |\n",
    "| iPhone 13 | 6.06 | 999 |\n",
    "| Galaxy Z Fold 3 | 7.6 | NaN |\n",
    "| OnePlus 9 Pro | 6.7 | 799 |\n",
    "| iPhone 12 Pro Max | 6.68 | NaN |\n",
    "\n",
    "- If prices are MCAR, then **the distribution of screen size should be the same** for:\n",
    "    - phones whose prices are missing, and \n",
    "    - phones whose prices aren't missing.\n",
    "- **We can use a permutation test to decide between MAR and MCAR!** We are asking the question, did these two samples come from the same underlying distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing MCAR\n",
    "\n",
    "Suppose you have a DataFrame with columns named `'col_1'`, `'col_2'`, ..., `'col_k'`, and want to test whether values in `'col_X'` are MCAR.\n",
    "\n",
    "The following _pseudocode_ describes an algorithm for testing whether `'col_X'`'s missingness is independent of all other columns in the DataFrame:\n",
    "\n",
    "```\n",
    "for i = 1, 2, ..., k, where i != X:\n",
    "    look at the distribution of col_i when col_X is missing\n",
    "    look at distribution of col_i when col_X is not missing\n",
    "    check if these two distributions are the same\n",
    "    if so, then col_X's missingness doesn't depend on col_i\n",
    "    if not, col_X is MAR dependent on col_i\n",
    "if all pairs of distributions were the same, \n",
    "then col_X is MCAR\n",
    "```\n",
    "\n",
    "We need to make precise what we mean by \"the same\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Heights\n",
    "\n",
    "- Let's load in Galton's heights dataset from DSC 10.\n",
    "- We will start with a complete dataset of child heights, child genders, and parent heights.\n",
    "- We will then **artifically introduce missing values** such that the values are MCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heights = pd.read_csv('data/midparent.csv')\n",
    "heights = heights.rename(columns={'childHeight': 'child'})\n",
    "heights = heights[['father', 'mother', 'gender', 'child']]\n",
    "heights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there currently aren't any missing values in `heights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have three numerical columns â€“ `'father'`, `'mother'`, and `'child'`. Let's visualize them simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(heights.drop('gender', axis=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulating MCAR data\n",
    "\n",
    "- We will make `'child'` MCAR by taking a random subset of `heights` and setting the corresponding `'child'` heights to `np.NaN`.\n",
    "- This is equivalent to flipping a (biased) coin for each row. \n",
    "    - If heads, we delete the `'child'` height.\n",
    "- **You will not do this in practice!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture)\n",
    "\n",
    "heights_mcar = heights.copy()\n",
    "idx = heights_mcar.sample(frac=0.3).index\n",
    "heights_mcar.loc[idx, 'child'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: Why is the value for `'child'` in the above Series not exactly 0.3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Verifying that child heights are MCAR in `heights_mcar`\n",
    "\n",
    "- Each row of `heights_mcar` belongs to one of two **groups**:\n",
    "    - Group 1: `'child'` is missing.\n",
    "    - Group 2: `'child'` is not missing.\n",
    "- We need to look at the distributions of every other column â€“ `'gender'`, `'mother'`, and `'father'` â€“ separately for these two groups, and check to see if they are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mcar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dist = (\n",
    "    heights_mcar\n",
    "    .assign(child_missing=heights_mcar['child'].isna())\n",
    "    .pivot_table(index='gender', columns='child_missing', aggfunc='size')\n",
    ")\n",
    "\n",
    "gender_dist = gender_dist / gender_dist.sum()\n",
    "gender_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that here, each column is a separate distribution that adds to 1.\n",
    "- The two columns look similar, which is evidence that `'child'`'s missingness does not depend on `'gender'`.\n",
    "    - Knowing that the child is `'female'` doesn't make it any more or less likely that their height is missing than knowing if the child is `'male'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`\n",
    "\n",
    "- In the previous slide, we saw that the distribution of `'gender'` is similar whether or not `'child'` is missing.\n",
    "- To make precise what we mean by \"similar\", we can run a permutation test. We are comparing two distributions:\n",
    "    1. Distribution of `'gender'` when `'child'` is missing.\n",
    "    2. Distribution of `'gender'` when `'child'` is not missing.\n",
    "- What test statistic do we use to compare categorical distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "gender_dist.plot(kind='barh', figsize=(5, 4), title='Gender by Missingness of Child Height');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Answer:** \n",
    "- Total variation distance.\n",
    "- However, with only two categories, the TVD is the same as the absolute difference in proportions for either category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulation\n",
    "\n",
    "The code to run our simulation largely looks the same as in previous permutation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "shuffled = heights_mcar.copy()\n",
    "shuffled['child_missing'] = shuffled['child'].isna()\n",
    "\n",
    "n_repetitions = 500\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling genders and assigning back to the DataFrame\n",
    "    shuffled['gender'] = np.random.permutation(shuffled['gender'])\n",
    "    \n",
    "    # Computing and storing TVD\n",
    "    pivoted = (\n",
    "        shuffled\n",
    "        .pivot_table(index='child_missing', columns='gender', aggfunc='size')\n",
    "        .apply(lambda x: x / x.sum(), axis=1)\n",
    "    )\n",
    "    \n",
    "    tvd = pivoted.diff().iloc[:, -1].abs().sum() / 2\n",
    "    tvds.append(tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_tvd = gender_dist.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "obs_tvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = np.mean(tvds >= obs_tvd)\n",
    "\n",
    "pd.Series(tvds).plot(kind='hist', density=True, ec='w', bins=10, title=f'p-value: {pval}', label='Simulated TVDs')\n",
    "plt.axvline(x=obs_tvd, color='red', linewidth=4, label='Observed TVD')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We fail to reject the null.\n",
    "- Recall, the null stated that the distribution of `'gender'` when `'child'` is missing is the same as the distribution of `'gender'` when `'child'` is not missing.\n",
    "- Hence, we conclude that the missingness in the `'child'` column is not dependent on `'gender'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'father'`\n",
    "\n",
    "- We again must compare two distributions:\n",
    "    1. Distribution of `'father'` when `'child'` is missing.\n",
    "    2. Distribution of `'father'` when `'child'` is not missing.\n",
    "- If the distributions are similar, we conclude that the missingness of `'child'` is not dependent on the height of the `'father'`.\n",
    "- We can again use a permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    heights_mcar\n",
    "    .assign(child_missing=heights_mcar['child'].isna())\n",
    "    .groupby('child_missing')['father']\n",
    "    .plot(kind='hist', density=True, alpha=0.75, ec='w', bins=20, legend=True, \n",
    "          title=\"Father's Height by Missingness of Child Height\")\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    heights_mcar\n",
    "    .assign(child_missing=heights_mcar['child'].isna())\n",
    "    .groupby('child_missing')['father']\n",
    "    .plot(kind='kde', legend=True, title=\"Father's Height by Missingness of Child Height\")\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concluding that `'child'` is MCAR\n",
    "\n",
    "- We need to run three permutation tests â€“ one for each column in `heights_mcar` other than `'child'`.\n",
    "- For every other column, if we **fail to reject the null** that the distribution of the column when `'child'` is missing is the same as the distribution of the column when `'child'` is not missing, then we can conclude `'child'` is MCAR.\n",
    "    - In such a case, its missingness is not tied to any other columns.\n",
    "    - For instance, knowing a child's father's height or gender doesn't make it any more or less likely that their height is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulating MAR data\n",
    "\n",
    "Now, we will make `'child'` heights MAR by deleting `'child'` heights according to a random procedure that **depends on other columns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture)\n",
    "\n",
    "def make_missing(r):\n",
    "    rand = np.random.uniform() # Random real number between 0 and 1\n",
    "    if r['father'] > 72 and rand < 0.5:\n",
    "        return np.NaN\n",
    "    elif r['gender'] == 'female' and rand < 0.3:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return r['child']\n",
    "    \n",
    "heights_mar = heights.copy()\n",
    "heights_mar['child'] = heights_mar.apply(make_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_mar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'gender'`, again\n",
    "\n",
    "This time, the distribution of `'gender'` in the two groups is very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dist = (\n",
    "    heights_mar\n",
    "    .assign(child_missing=heights_mar['child'].isna())\n",
    "    .pivot_table(index='gender', columns='child_missing', aggfunc='size')\n",
    ")\n",
    "\n",
    "gender_dist = gender_dist / gender_dist.sum()\n",
    "gender_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dist.plot(kind='barh', figsize=(5, 4), title='Gender by Missingness of Child Height');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question:** If we take the average of the non-null `'child'` heights in the dataset with missing values, will it be less than or greater than the average `'child'` height in the full dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer:** \n",
    "Because: \n",
    "    - `'child'` height tends to be missing much more frequently when the child is `'female'`, and \n",
    "    - adult females tend to be shorter than adult males on average, \n",
    "    - the average `'child'` height in the dataset with missing values will be **less than** the average `'child'` height in the full dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing null and non-null `'child'` distributions for `'father'`, again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    heights_mar\n",
    "    .assign(child_missing=heights_mar['child'].isna())\n",
    "    .groupby('child_missing')['father']\n",
    "    .plot(kind='kde', legend=True, title=\"Father's Height by Missingness of Child Height\")\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Observation:**\n",
    "- The above two distributions look quite different.\n",
    "    - This is because we artificially created missingness in the dataset in a way that depended on `'father'` and `'gender'`.\n",
    "- However, their difference in means is likely small.\n",
    "- If we ran a permutation test with the difference in means as our test statistic, our observed test statistic would be very small.\n",
    "    - **Using just the difference in means, it is hard to tell these two distributions apart.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Kolmogorov-Smirnov test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: permutation tests\n",
    "\n",
    "- Permutation tests help decide whether **two samples came from the same distribution**.\n",
    "- In a permutation test, we simulate data under the null by **shuffling** either group labels or numerical features.\n",
    "    - In effect, this **randomly assigns individuals to groups**.\n",
    "- If the two distributions are **quantitative (numerical)**, we use as our test statistic the **difference in group means or medians**.\n",
    "- If the two distributions are **qualitative (categorical)**, we use as our test statistic the **total variation distance (TVD)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Difference in means\n",
    "\n",
    "The difference in means works well in some cases. Let's look at one such case.\n",
    "\n",
    "Below, we artificially generate two numerical datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture)\n",
    "\n",
    "N = 1000 # number of samples for each distribution\n",
    "\n",
    "# Distribution 'A'\n",
    "distr1 = pd.Series(np.random.normal(0, 1, size=N//2))\n",
    "\n",
    "# Distribution 'B'\n",
    "distr2 = pd.Series(np.random.normal(3, 1, size=N//2))\n",
    "\n",
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanA, meanB = data.groupby('group')['data'].mean().round(7).tolist()\n",
    "title = f'mean of A: {meanA}\\n mean of B: {meanB}'\n",
    "\n",
    "data.groupby('group')['data'].plot(kind='kde', legend=True, title=title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "- So far, we have used the difference in means as our test statistic in quantitative permutation tests.\n",
    "- We've concluded that **two distributions were likely different if their means were different**.\n",
    "- Can you think of two **different** distributions that have the same mean? ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different distributions with the same mean\n",
    "\n",
    "Let's generate two distributions that look very different but have the same mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) # So that we get the same results each time (for lecture)\n",
    "\n",
    "N = 1000 # number of samples for each distribution\n",
    "\n",
    "# Distribution 'A'\n",
    "a = pd.Series(np.random.normal(0, 1, size=N//2))\n",
    "b = pd.Series(np.random.normal(4, 1, size=N//2))\n",
    "distr1 = pd.concat([a,b], ignore_index=True)\n",
    "\n",
    "# Distribution 'B'\n",
    "distr2 = pd.Series(np.random.normal(distr1.mean(), distr1.std(), size=N))\n",
    "\n",
    "data = pd.concat([distr1, distr2], axis=1, keys=['A', 'B']).unstack().reset_index().drop('level_1', axis=1)\n",
    "data = data.rename(columns={'level_0': 'group', 0: 'data'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanA, meanB = data.groupby('group')['data'].mean().round(7).tolist()\n",
    "title = f'mean of A: {meanA}\\n mean of B: {meanB}'\n",
    "\n",
    "data.groupby('group')['data'].plot(kind='kde', legend=True, title=title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if we use the difference in means as our test statistic in a permutation test, we will fail to reject the null that the two distributions are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = data.copy()\n",
    "\n",
    "diff_means = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the data and assigning it back to the DataFrame\n",
    "    shuffled['data'] = np.random.permutation(shuffled['data'])\n",
    "    \n",
    "    # Computing and storing the absolute difference in means\n",
    "    diff_mean = shuffled.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "    diff_means.append(diff_mean)\n",
    "    \n",
    "diff_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_diff = data.groupby('group')['data'].mean().diff().abs().iloc[-1]\n",
    "pval = np.mean(np.array(diff_means) >= obs_diff)\n",
    "\n",
    "pd.Series(diff_means).plot(kind='hist', density=True, ec='w', bins=20, title=f'p-value: {pval}', label='Simulated Absolute Differences in Means')\n",
    "plt.axvline(obs_diff, color='red', label='Observed Difference in Means')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Telling quantitative distributions apart\n",
    "\n",
    "- The difference in means only works as a test statistic in permutation tests **if the two distributions have similar shapes**.\n",
    "    - It tests to see if one is a shifted version of the other.\n",
    "- We need a better test statistic to differentiate between quantitative distributions with different shapes.\n",
    "- In other words, we need a **distance** metric between quantitative distributions.\n",
    "    - The TVD is a distance metric between categorical distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('group')['data'].plot(kind='kde', legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Kolmogorov-Smirnov test statistic\n",
    "\n",
    "- The K-S test statistic measures the similarity between two distributions.\n",
    "- It is defined in terms of the **cumulative distribution function (CDF)** of a given distribution.\n",
    "    - If $f(x)$ is a distribution, then the CDF $F(x)$ is the proportion of values in distribution $f$ that are less than or equal to $x$.\n",
    "- The K-S statistic is roughly defined as the **largest difference between two CDFs**.\n",
    "<center><img src=./imgs/KS2_Example.png width=50%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: cumulative distribution functions\n",
    "\n",
    "Let's look at the CDFs of our two synthetic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data\n",
    "data.groupby('group')['data'].plot(kind='kde', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and figure out how this code works!\n",
    "gpA = data.loc[data['group'] == 'A', 'data']\n",
    "gpB = data.loc[data['group'] == 'B', 'data']\n",
    "\n",
    "plt.plot(gpA.value_counts(normalize=True).sort_index().cumsum(), label='CDF of A')\n",
    "plt.plot(gpB.value_counts(normalize=True).sort_index().cumsum(), label='CDF of B')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The K-S statistic in Python\n",
    "\n",
    "Fortunately, **we don't need to calculate the K-S statistic ourselves**! Python can do it for us (and you can use this pre-built version in all assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ks = ks_2samp(gpA, gpB).statistic\n",
    "obs_ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know if this number is big or small. We need to run a permutation test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "shuffled = data.copy()\n",
    "\n",
    "ks_stats = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the data and assigning it back to the DataFrame\n",
    "    shuffled['data'] = np.random.permutation(shuffled['data'])\n",
    "    \n",
    "    # Computing and storing the K-S statistic\n",
    "    groups = shuffled.groupby('group')['data']\n",
    "    ks_stat = ks_2samp(groups.get_group('A'), groups.get_group('B')).statistic\n",
    "    ks_stats.append(ks_stat)\n",
    "    \n",
    "ks_stats[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = np.mean(np.array(ks_stats) >= obs_ks)\n",
    "\n",
    "pd.Series(ks_stats).plot(kind='hist', density=True, ec='w', title=f'p-value: {pval}', label='Simulated K-S Statistics')\n",
    "plt.axvline(obs_diff, color='red', label='Observed K-S Statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to differentiate between the two distributions using the K-S test statistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `ks_2samp`\n",
    "\n",
    "* `scipy.stats.ks_2samp` actually returns **both** the statistic **and** a p-value.\n",
    "* The p-value is calculated using the permutation test we just performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(gpA, gpB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Difference in means vs. K-S statistic\n",
    "\n",
    "- The K-S statistic measures the difference between two distributions.\n",
    "- It **does not** quantify if one is larger than the other on average, so there are times we still need to use the difference in means.\n",
    "- Strategy: Always plot the two distributions you are comparing.\n",
    "    - If the distributions have similar shapes but are centered in different places, use the difference in means (or absolute difference in means).\n",
    "    - If your alternative hypothesis involves a \"direction\" (i.e. smoking weights were are on average than non-smoking weights), use the difference in means.\n",
    "    - If the distributions have different shapes and your alternative hypothesis is simply that the two distributions are different, use the K-S statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More examples\n",
    "\n",
    "***Note:*** We are not going to get to these slides in class. They're just here to provide more examples of missingness mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: NMAR \n",
    "\n",
    "* Can you make a reasonable case that the differences in missing vs not missing is largely explainable via *observed* data?\n",
    "    - If yes, then the missing data (column) 'missing at random' and the missing data is 'ignorable' (when handled properly).\n",
    "    - If no, then the missing data is 'not missing at random' (NMAR), or 'non-ignorable'. You must explicitly model missingness using assumptions on the data generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: MAR\n",
    "\n",
    "* If missingness is explainable via *observed* data, then the missing data is 'missing at random' (MAR).\n",
    "* The distribution of missing data may still look different than the observed data!\n",
    "    - MAR requires you to understand how the missingness is dependent on other attributes in your data.\n",
    "* Use permutation tests to assess the dependence of missing data on other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: MCAR\n",
    "\n",
    "* If missingness doesn't depend on any values in the observed data, it is 'unconditionally ignorable' (MCAR).\n",
    "* MCAR is equivalent to data being MAR, without dependence on any other columns.\n",
    "* If permutation tests point toward similar distributions of missing vs not-missing data, for *every* other column, then the data *may* be MCAR.\n",
    "    - Caution: you can't assert the data *are* MCAR, as permutation tests don't allow you to accept the null hypothesis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Cars\n",
    "\n",
    "* We have data on cars that were given tickets.\n",
    "* For each car, we have their `'vin'` number, `'car_make'`, `'car_year'`, and `'car_color'`.\n",
    "* **Question:** Is `'car_color'` missing at random, **dependent on `'car_year'`**?\n",
    "    * Is the distribution of `'car_year'` similar when color is missing vs. not missing?\n",
    "    * How similar is similar enough?\n",
    "    \n",
    "Let's use a permutation test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('data/cars.csv')\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of car colors missing\n",
    "cars['car_color'].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['color_missing'] = cars['car_color'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    cars\n",
    "    .pivot_table(index='car_year', columns='color_missing', values=None, aggfunc='size')\n",
    "    .fillna(0)\n",
    "    .apply(lambda x: x / x.sum())\n",
    "    .plot(title='Distribution of Car Years by Missingness of Color')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These distributions look pretty similar. We won't run the permutation test here, but if we did, we'd fail to reject the null. It doesn't seem like the missingness of `'car_color'` depends on `'car_year'`.\n",
    "- To figure out if the missingness of `'car_color'` is MCAR, we'd need to do a similar analysis for all other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missingness of `'car_color'` on `'car_make'`\n",
    "\n",
    "Let's test whether the missingness of `'car_color'` is dependent on `'car_make'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_distributions = (\n",
    "    cars\n",
    "    .pivot_table(index='car_make', columns='color_missing', values=None, aggfunc='size')\n",
    "    .fillna(0)\n",
    "    .apply(lambda x: x / x.sum())\n",
    ")\n",
    "\n",
    "# There are too many makes to plot thema ll at once!\n",
    "emp_distributions.iloc[:20].plot(kind='barh', title='Distribution of Makes by Missingness of Color');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_tvd = emp_distributions.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = cars.copy()[['car_make', 'color_missing']]\n",
    "\n",
    "n_repetitions = 500\n",
    "tvds = []\n",
    "\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    # Shuffling the colors and assigning them to the DataFrame\n",
    "    shuffled['car_make'] = np.random.permutation(shuffled['car_make'])\n",
    "    \n",
    "    # Computing and storing the TVD\n",
    "    pivoted = (\n",
    "        shuffled\n",
    "        .pivot_table(index='car_make', columns='color_missing', values=None, aggfunc='size')\n",
    "        .fillna(0)\n",
    "        .apply(lambda x: x / x.sum())\n",
    "    )\n",
    "    \n",
    "    tvd = pivoted.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "    tvds.append(tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = np.mean(tvds >= observed_tvd)\n",
    "\n",
    "pd.Series(tvds).plot(kind='hist', density=True, ec='w', bins=10, title=f'p-value: {pval}', label='Simulated TVDs')\n",
    "plt.axvline(x=observed_tvd, color='red', linewidth=4, label='Observed TVD')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we fail to reject the null that the distribution of `'car_make'` is the same whether or not `'car_color'` is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Assessing missingness in payments data\n",
    "\n",
    "* We have payment information for purchases: credit card type, credit card number, date of birth.\n",
    "* Is the credit card number missing at random dependent on the type of card?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = pd.read_csv('data/payment.csv')\n",
    "payments['cc_isnull'] = payments['credit_card_number'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_distributions = (\n",
    "    payments\n",
    "    .pivot_table(columns='cc_isnull', index='credit_card_type', aggfunc='size')\n",
    "    .fillna(0)\n",
    "    .apply(lambda x:x / x.sum())\n",
    ")\n",
    "\n",
    "emp_distributions.plot(kind='barh', title='distribution of card types');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_tvd = np.sum(np.abs(emp_distributions.diff(axis=1).iloc[:,-1])) / 2\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "payments_type = payments.copy()[['credit_card_type', 'cc_isnull']]\n",
    "tvds = []\n",
    "for _ in range(n_repetitions):\n",
    "    \n",
    "    shuffled_types = (\n",
    "        payments_type['credit_card_type']\n",
    "        .sample(replace=False, frac=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    shuffled = (\n",
    "        payments_type\n",
    "        .assign(**{'Shuffled Types': shuffled_types})\n",
    "    )\n",
    "    \n",
    "    # compute the tvd\n",
    "    shuffed_emp_distributions = (\n",
    "        shuffled\n",
    "        .pivot_table(columns='cc_isnull', index='Shuffled Types', values=None, aggfunc='size')\n",
    "        .fillna(0)\n",
    "        .apply(lambda x:x/x.sum())\n",
    "    )\n",
    "    \n",
    "    tvd = np.sum(np.abs(shuffed_emp_distributions.diff(axis=1).iloc[:,-1])) / 2\n",
    "    # add it to the list of results\n",
    "    \n",
    "    tvds.append(tvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: assessing missingness in payments data\n",
    "\n",
    "* Is the credit card number missing at random dependent on the type of card?\n",
    "* As always, set significance level **beforehand**:\n",
    "    - How important is the column in the modeling process?\n",
    "    - How many null values are there?\n",
    "* Consideration: how important is a faithful imputation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: visualize\n",
    "pd.Series(tvds).plot(kind='hist', density=True, alpha=0.8)\n",
    "plt.scatter(observed_tvd, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value\n",
    "np.count_nonzero(tvds <= observed_tvd) / len(tvds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: assessing missingness in payments data\n",
    "\n",
    "* Is the credit card number missing at random dependent on the age of shopper?\n",
    "* For quantitative distributions, we've compared means of two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payments['date_of_birth'] = pd.to_datetime(payments.date_of_birth)\n",
    "payments['age'] = (2019 - payments.date_of_birth.dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are the distributions similar?\n",
    "# Where are the differences? Are they noise, or real?\n",
    "payments.groupby('cc_isnull').age.plot(kind='kde', title='distribution of ages by missingness of CC', legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(\n",
    "    payments.groupby('cc_isnull')['age'].get_group(True),\n",
    "    payments.groupby('cc_isnull')['age'].get_group(False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary, next time\n",
    "\n",
    "- We can use permutation tests to verify if a column is MAR vs. MCAR.\n",
    "    - Create two groups: one where values in a column are missing, and another where values in a column aren't missing.\n",
    "    - To test the missingness of column X:\n",
    "        - For every other column, test the null hypothesis \"the distribution of (other column) is the same when column X is missing and when column X is not missing.\"\n",
    "        - If you fail to reject the null, then column X's missingness does not depend on (other column).\n",
    "        - If you reject the null, then column X is MAR dependent on (other column).\n",
    "        - **If you fail to reject the null for all other columns, then column X is MCAR!**\n",
    "\n",
    "- **Next time:** Using missingness types to **impute** data (not on the Midterm Exam)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
