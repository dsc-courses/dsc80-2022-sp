{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from IPython.display import HTML, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 15 ‚Äì Requests and Parsing HTML\n",
    "\n",
    "## DSC 80, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Project 3 is released, and is due on **Thursday, May 12th at 11:59PM**.\n",
    "    - See [dsc80.com/project3](https://dsc80.com/project3/) for all the details.\n",
    "- Midterm Exam grades are released! See [#935](https://campuswire.com/c/G325FA25B/feed/935) for details.\n",
    "- Lab 5 is due **today at 11:59PM**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- APIs and web scraping.\n",
    "- The anatomy of HTML documents.\n",
    "- Parsing HTML via Beautiful Soup.\n",
    "- Example: Scraping the HDSI Faculty page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## APIs and web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Programmatic requests\n",
    "\n",
    "* We learned how to use the Python `requests` package to exchange data via HTTP.\n",
    "    - `GET` requests are used to request data **from** a server.\n",
    "    - `POST` requests are used to **send** data to a server. \n",
    "* There are two ways of collecting data via requests:\n",
    "    * By using a published API (application programming interface).\n",
    "    * By scraping a webpage to collect its HTML source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### APIs\n",
    "\n",
    "* An API is a service that makes data directly available to the user in a convenient fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Advantages:\n",
    "    - The data are usually clean, up-to-date, and ready to use.\n",
    "    - The presence of a API signals that the data provider is okay with you using their data.\n",
    "    - The data provider can plan and regulate data usage.\n",
    "        - Some APIs require you to create an API \"key\", which is like an account for using the API.\n",
    "        - APIs can also give you access to data that isn't publicly available on a webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Disadvantages:\n",
    "    - APIs don't always exist for the data you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### API terminology\n",
    "\n",
    "- A URL, or uniform resource locator, describes the location of a website or resource.\n",
    "\n",
    "- An **API endpoint** is a URL of the data source that the user wants to make requests to.\n",
    "\n",
    "- For example, on the [Reddit API](https://www.reddit.com/dev/api/):\n",
    "    * the `/comments` endpoint retrieves information about comments.\n",
    "    * the `/hot` endpoint retrieves data about posts labeled \"hot\" right now. \n",
    "    - To access these endpoints, you add the endpoint name to the base URL of the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### API requests\n",
    "\n",
    "- API requests are just `GET`/`POST` requests to a specially maintained URL.\n",
    "- Let's test out the [Pok√©mon API](https://pokeapi.co)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's make a `GET` request for `'squirtle'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://pokeapi.co/api/v2/pokemon/squirtle')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the 200 status code is good! Let's take a look at the **content**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like JSON. We can extract the JSON from this request with the `json` method (or by passing `r.text` to `json.loads`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try a `GET` request for `'billy'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://pokeapi.co/api/v2/pokemon/billy')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scraping\n",
    "\n",
    "* Scraping is the act of programmatically \"browsing\" the web, downloading the source code (HTML) of pages that you're interested in extracting data from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Advantages:\n",
    "    * You can always do it!\n",
    "        - e.g. Google scrapes webpages in order to make them searchable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Disadvantages:\n",
    "    - It is often difficult to parse and clean scraped data.\n",
    "        - Source code often includes a lot of content unrelated to the data you're trying to find (e.g. formatting, advertisements, other text).\n",
    "    - Websites can change often, so scraping code can get outdated quickly.\n",
    "    - Websites may not want you to scrape their data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In general, we prefer APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accessing HTML\n",
    "\n",
    "Let's make a `GET` request to the HDSI Faculty page and see what the resulting HTML looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://datascience.ucsd.edu/about/faculty/faculty/'\n",
    "r = requests.get(url)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlText = r.text\n",
    "len(urlText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(urlText[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wow, that is gross looking! üò∞ \n",
    "\n",
    "- It is **raw** HTML, which web browsers use to display websites.\n",
    "- The information we are looking for ‚Äì faculty information ‚Äì is in there somewhere, but we have to search for it and extract it, which we wouldn't have to do if we had an API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Best practices for scraping\n",
    "\n",
    "1. **Send requests slowly** and be upfront about what you are doing!\n",
    "2. Respect the policy published in the page's `robots.txt` file.\n",
    "    - Many sites have a `robots.txt` file in their root directory, which contains a policy that allows or disallows automatic access to their site. \n",
    "    - See [here](https://moz.com/learn/seo/robotstxt) or Lab 5, Question 5 for more details.\n",
    "3. Don't spoof your User-agent (i.e. don't try to trick the server into thinking you are a person).\n",
    "4. Read the Terms of Service for the site and follow it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consequences of irresponsible scraping\n",
    "\n",
    "If you make too many requests:\n",
    "* The server may block your IP Address.\n",
    "    - Everyone in your dorm might lose access to Google! (Seriously!)\n",
    "* You may take down the website.\n",
    "    - A journalist scraped and accidentally took down the Cook County Inmate Locater.\n",
    "    - As a result, inmate's families weren't able to contact them while the site was down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The anatomy of HTML documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is HTML?\n",
    "\n",
    "* HTML (HyperText Markup Language) is **the** basic building block of the internet. \n",
    "* It defines the content and layout of a webpage, and as such, it is what you get back when you scrape a webpage.\n",
    "* See [this tutorial](http://fab.academany.org/2018/labs/fablaboshanghai/students/bob-wu/Fabclass/week2_project_management/HTML.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!cat data/lec15_ex1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The anatomy of HTML documents\n",
    "\n",
    "* **HTML document**: The totality of markup that makes up a webpage.\n",
    "\n",
    "* **Document Object Model (DOM)**: The internal representation of a HTML document as a hierarchical **tree** structure.\n",
    "\n",
    "* **HTML element**: An object in the DOM, such as a paragraph, header, or title.\n",
    "* **HTML tags**: Markers that denote the **start** and **end** of an element, such as `<p>` and `</p>`.\n",
    "\n",
    "<center><img src='imgs/dom.jpg'></center>\n",
    "\n",
    "<center><a href='https://simplesnippets.tech/what-is-document-object-modeldom-how-js-interacts-with-dom/'>(source)</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Useful tags to know\n",
    "\n",
    "\n",
    "|Element|Description|\n",
    "|:---|:---|\n",
    "|`<html>`|the document|\n",
    "|`<head>`|the header|\n",
    "|`<body>`|the body|\n",
    "|`<div>` |a logical division of the document|\n",
    "|`<span>`|an *in-line* logical division|\n",
    "|`<p>`|a paragraph|\n",
    "| `<a>`| an anchor (hyper-link)|\n",
    "|`<h1>, <h2>, ...`| header(s) |\n",
    "|`<img>`| an image |\n",
    "\n",
    "There are many, many more. See [this article](https://en.wikipedia.org/wiki/HTML_element) for examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: images and hyperlinks\n",
    "\n",
    "Tags can have **attributes**, which further specify how to display information on a webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For instance, `<img>` tags have `src` and `alt` attributes (among others):\n",
    "\n",
    "```html\n",
    "<img src=\"billy-selfie.png\" alt=\"A photograph of Billy.\" width=500>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hyperlinks have `href` attributes: \n",
    "\n",
    "```html\n",
    "Click <a href=\"https://dsc80.com/project3\">this link</a> to access Project 3.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do you think this webpage looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec15_ex2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `<div>` tag\n",
    "\n",
    "```html\n",
    "<div style=\"background-color:lightblue\">\n",
    "  <h3>This is a heading</h3>\n",
    "  <p>This is a paragraph.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "* The `<div>` tag defines a division or a \"section\" of an HTML document.\n",
    "    * Think of a `<div>` as a \"cell\" in a Jupyter Notebook.\n",
    "\n",
    "* The `<div>` element is often used as a container for other HTML elements to style them with CSS or to perform operations involving them using JavaScript.\n",
    "\n",
    "* `<div>` elements often have attributes, which are important when scraping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Document trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/lec15_ex1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Under the document object model (DOM), HTML documents are trees. In DOM trees, child nodes are **ordered**.\n",
    "\n",
    "<center>\n",
    "\n",
    "<img src=\"imgs/webpage_anatomy.png\" width=\"50%\">\n",
    "\n",
    "</center>    \n",
    "\n",
    "What does the DOM tree look like for this document?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/dom_tree.png\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Quote scraping\n",
    "\n",
    "Consider the following webpage.\n",
    "\n",
    "<center><img src=\"imgs/quotes2scrape.png\" width=60%></center>\n",
    "\n",
    "- What do you think the DOM tree looks like?\n",
    "- If you had to store the data on this page in a DataFrame, what would the rows and columns represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/quote_dom.png\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parsing HTML via Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Beautiful Soup üçú\n",
    "\n",
    "* [Beautiful Soup 4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a Python HTML parser.\n",
    "    - To \"parse\" means to \"extract meaning from a sequence of symbols\".\n",
    "* **Warning:** Beautiful Soup 4 and Beautiful Soup 3 work differently, so make sure you are using and looking at documentation for Beautiful Soup 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example HTML document\n",
    "\n",
    "To start, let's instantiate a `BeautifulSoup` object, using the source code for an HTML page with the DOM tree shown below:\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The string `html_string` contains an HTML \"document\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<html>\n",
    "    <body>\n",
    "      <div id=\"content\">\n",
    "        <h1>Heading here</h1>\n",
    "        <p>My First paragraph</p>\n",
    "        <p>My <em>second</em> paragraph</p>\n",
    "        <hr>\n",
    "      </div>\n",
    "      <div id=\"nav\">\n",
    "        <ul>\n",
    "          <li>item 1</li>\n",
    "          <li>item 2</li>\n",
    "          <li>item 3</li>\n",
    "        </ul>\n",
    "      </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `HTML` function in the `IPython.display` module, we can render an HTML document from within our Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `BeautifulSoup` objects\n",
    "\n",
    "`bs4.BeautifulSoup` takes in a string or file-like object representing HTML (`markup`) and returns a **parsed** document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs4.BeautifulSoup?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we pass the result of a `GET` request to `bs4.BeautifulSoup`, but here we will pass our hand-crafted `html_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(html_string)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BeautifulSoup` objects have several useful attributes, e.g. `text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Child nodes\n",
    "\n",
    "- Recall, HTML documents are represented as trees.\n",
    "    - Each page element becomes a node in this tree.\n",
    "- A `BeautifulSoup` object represents a **node** in the tree.\n",
    "    - Each `BeautifulSoup` object has 0 or more child nodes.\n",
    "    - To access the children of a node, use the `children` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: iterators\n",
    "\n",
    "On the previous slide, we saw that that `soup.children` isn't another `BeautifulSoup` object, but rather something of the form `<list_iterator at 0x7f7b0ab8c370>`.\n",
    "\n",
    "What are [iterators](https://www.w3schools.com/python/python_iterators.asp), again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1, 2, 3, 4]\n",
    "double = map(lambda x: x ** 2, nums)\n",
    "double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Child nodes\n",
    "\n",
    "The `children` attribute returns an iterator so that it doesn't have to load the entire DOM tree in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(soup.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = next(soup.children)\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(root.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(root.children)[1].children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(list(root.children)[1].children)[3].children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Depth-first traversal through `descendants`\n",
    "\n",
    "- While we could use the `children` attribute to navigate to any node in a `BeautifulSoup` tree, there are easier ways of navigating the tree.\n",
    "\n",
    "- The `descendants` attribute traverses a `BeautifulSoup` tree using **depth-first traversal**.\n",
    "    - Why depth-first? Elements closer to one another on a page are more likely to be related than elements further away.\n",
    "    - Question: What type of depth-first traversal does this use ‚Äì preorder, inorder, or postorder traversal?\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in soup.descendants:\n",
    "    # print(child) # What would happen if we ran this instead?\n",
    "    if isinstance(child, str):\n",
    "        continue\n",
    "    print(child.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding elements in a tree\n",
    "\n",
    "Practically speaking, you will not use the `children` or `descendants` attributes directly very often. Instead, you will use the following methods:\n",
    "\n",
    "- `soup.find(tag)`, which finds the **first** instance of a tag (the first one on the page, i.e. the first one that DFS sees).\n",
    "    - More general: `soup.find(name=None, attrs={}, recursive=True, text=None, **kwargs)`.\n",
    "- `soup.find_all(tag)` will find **all** instances of a tag.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `find`\n",
    "\n",
    "Let's try and extract the first `<div>` subtree.\n",
    "\n",
    "<center><img src=\"imgs/dom_tree_1.png\" width=\"60%\"></center>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find('div')\n",
    "div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"imgs/dom_subtree_1.png\" width=\"30%\"></center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and find the `<div>` element that has an `id` attribute equal to `'nav'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', attrs={'id': 'nav'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find` will return the first occurrence of a tag, regardless of what depth it is in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('ul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `find_all`\n",
    "\n",
    "`find_all` returns a list of all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.text for x in soup.find_all('li')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text` is a node attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Node attributes\n",
    "* The `text` attribute of a tag element gets the text between the opening and closing tags.\n",
    "* The `attrs` attribute lists all attributes of a tag.\n",
    "* The `get(key)` method gets the value of a tag attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can access tags using attribute notation, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.html.div.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.html.div.h1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.html.div.next_sibling.next_sibling.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Scraping the HDSI Faculty page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Let's try and extract a list of HDSI Faculty from https://datascience.ucsd.edu/about/faculty/faculty/.\n",
    "\n",
    "A good first step is to use the \"inspect element\" tool in our web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_response = requests.get('https://datascience.ucsd.edu/about/faculty/faculty/')\n",
    "fac_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(fac_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It seems like the relevant `<div>`s for faculty are the ones where the `data-entry-type` attribute is equal to `'individual'`. Let's find all of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "divs = soup.find_all('div', attrs={'data-entry-type': 'individual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within here, we need to extract each faculty member's name. It seems like names are stored in the `title` attribute within an `<a>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('a').get('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract job titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('h4').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And bios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('div', attrs={'class': 'cn-bio'}).text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's create a DataFrame consisting of names and bios for each faculty member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = [div.find('a').get('title') for div in divs]\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [div.find('h4').text if div.find('h4') else '' for div in divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios = [div.find('div', attrs={'class': 'cn-bio'}).text.strip() for div in divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty = pd.DataFrame().assign(name=names, title=titles, bio=bios)\n",
    "faculty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty[faculty['title'] == 'Lecturer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we want to get faculty members' pictures? It seems like we should look at the attributes of an `<img>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_picture(name):\n",
    "    idx = names.index(name)\n",
    "    url = divs[idx].find('img').get('srcset')\n",
    "    url = 'https://' + url.strip('/').strip(' 1x')\n",
    "    display(Image(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_picture('Suraj Rampure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- APIs allow us to request information from web servers in a convenient fashion.\n",
    "- When APIs don't exist, we instead scrape webpages to access their source HTML and then parse the HTML to extract the information we care about.\n",
    "- Under the document object model (DOM), HTML documents are trees.\n",
    "    - Elements are defined by tags.\n",
    "- Beautiful Soup is an HTML parser that allows us to (somewhat) easily extract information from HTML documents.\n",
    "    - `soup.find` and `soup.find_all` are the functions you will use most often.\n",
    "- **Next time:** Another scraping example. Regular expressions."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
