{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 9 ‚Äì Combining Data\n",
    "\n",
    "## DSC 80, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Discussion 3 is due (for extra credit!) **tomorrow at 11:59PM**.\n",
    "- Lab 3 is due on **Monday, April 18th 11:59PM**.\n",
    "    - Check [here](https://campuswire.com/c/G325FA25B/feed/507) for clarifications.\n",
    "- Lab 1 (+more) grades are released ‚Äì see [this post](https://campuswire.com/c/G325FA25B/feed/509) for details, and [this post](https://campuswire.com/c/G325FA25B/feed/508) for assignment solutions.\n",
    "- Watch [this video üé•](https://www.youtube.com/watch?v=uUawZfAgA64) for tips on how to work with the command-line.\n",
    "- Project 2 will be released this weekend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Concatenating vertically.\n",
    "- Concatenating horizontally.\n",
    "- Joining and merging.\n",
    "- Working with time series data.\n",
    "\n",
    "Good resource: `pandas` [User Guide](https://pandas.pydata.org/docs/user_guide/merging.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap: Concatenating vertically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Grades\n",
    "\n",
    "By default, `pd.concat` stacks DataFrames row-wise, i.e. on top of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_A = pd.DataFrame({\n",
    "    'Name': ['Annie', 'Billy', 'Sally', 'Tommy'],\n",
    "    'Midterm': [98, 82, 23, 45],\n",
    "    'Final': [88, 100, 99, 67]\n",
    "})\n",
    "\n",
    "section_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_B = pd.DataFrame({\n",
    "    'Name': ['Junior', 'Rex', 'Flash'],\n",
    "    'Midterm': [70, 99, 81],\n",
    "    'Final': [42, 25, 90]\n",
    "})\n",
    "\n",
    "section_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `pd.concat` on a list of the above two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([section_A, section_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ‚ö†Ô∏è Warning: No loops!\n",
    "\n",
    "- `pd.concat` returns a copy; it does not modify any of the input DataFrames.\n",
    "- Do **not** use `pd.concat` in a loop, as it has terrible time and space efficiency.\n",
    "\n",
    "```py\n",
    "total = pd.DataFrame()\n",
    "for df in dataframes:\n",
    "    total = total.concat(df)\n",
    "```\n",
    "\n",
    "- Instead, use `pd.concat(dataframes)`, where `dataframes` is a list of DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concatenating horizontally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Grades (again)\n",
    "\n",
    "Suppose we have two DataFrames, `exams` and `assignments`, which both contain different attributes for the same individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams = section_A.copy()\n",
    "exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = exams[['Name']].assign(Homeworks=[99, 45, 23, 81],\n",
    "                                     Labs=[100, 100, 99, 100])\n",
    "\n",
    "assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to combine these DataFrames with `pd.concat`, we don't quite get what we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams, assignments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's where the `axis` argument becomes handy. \n",
    "\n",
    "Remember, most `pandas` operations default to `axis=0`, but here we want to concatenate the columns of `exams` to the columns of `assignments`, so we should use `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams, assignments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `'Name'` column appears twice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concatenating horizontally\n",
    "\n",
    "- To concatenate two DataFrames horizontally, use `pd.concat` with `axis=1`.\n",
    "- Concatenation is done by matching indexes, regardless of their order. **It does not look at any column values!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/merging_concat_series_ignore_index.png' width='80%'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the call to `pd.concat` below works as expected, even though the orders of the names in `exams_by_name` and `assignments_by_name` are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# .loc[::-1] reverses the rows of the DataFrame\n",
    "exams_by_name = exams.set_index('Name').loc[::-1]\n",
    "exams_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_by_name = assignments.set_index('Name')\n",
    "assignments_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams_by_name, assignments_by_name], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember that `pd.concat` only looks at the index when combining rows, not at any other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams_reversed = exams.loc[::-1].reset_index(drop=True)\n",
    "exams_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams_reversed, assignments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing rows?\n",
    "\n",
    "If we concatenate two DataFrames that don't share row indexes, `NaN`s are added in the rows that aren't shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams_extra = exams.copy()\n",
    "exams_extra.loc[4] = ['Junior', 100, 100]\n",
    "exams_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams_extra, assignments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: `pd.concat`\n",
    "\n",
    "- `pd.concat` \"stitches\" two or more DataFrames together.\n",
    "- If you use `axis=0`, the DataFrames are concatenated **vertically** based on column names (rows on top of rows).\n",
    "- If you use `axis=1`, the DataFrames are concatenated **horizontally** based on row indexes (columns next to columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Joining and merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concatenating horizontally\n",
    "\n",
    "- `pd.concat` with `axis=1` combines DataFrames horizontally.\n",
    "- To combine DataFrames horizontally in more advanced ways, we perform a **join** (also known as a **merge**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Joins\n",
    "\n",
    "- A **join** creates a new DataFrame by combining the rows of two DataFrames.\n",
    "- A join is appropriate when we have two sources of information\n",
    "    - about the same individuals, that is\n",
    "    - linked by a common column.\n",
    "- The common column is called the **join key**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Here, the join key is `'Player Id'`.\n",
    "\n",
    "<center><img src=\"imgs/join.png\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `merge` method\n",
    "\n",
    "- The `merge` DataFrame method joins two tables by columns or indexes.\n",
    "    - \"Merge\" is just `pandas`' word for \"join\".\n",
    "    - It also exists as a `pandas` function.\n",
    "- If join keys are not specified, all shared columns between the two DataFrames are used by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's work with a small example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = pd.DataFrame({\n",
    "    'City': ['San Diego', 'Toronto', 'Rome'],\n",
    "    'Temperature': [76, 28, 56]\n",
    "})\n",
    "\n",
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.DataFrame({\n",
    "    'City': ['Toronto', 'Shanghai', 'San Diego'],\n",
    "    'Country': ['Canada', 'China', 'USA']\n",
    "})\n",
    "\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't specify which columns to merge on, so it defaulted to `'City'`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Join types: inner joins\n",
    "\n",
    "- Note that `'Rome'` and `'Shanghai'` do not appear in the merged DataFrame.\n",
    "- This is because there is:\n",
    "    - no city named `'Rome'` in the second DataFrame, and\n",
    "    - no city named `'Shanghai'` in the first DataFrame.\n",
    "- The default type of join that `merge` performs is an **inner join**, which keeps the **intersection** of the join keys.\n",
    "\n",
    "\n",
    "<center><img src='imgs/image_0.png' width=40%></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different join types handle mismatches differently\n",
    "\n",
    "There are four types of joins.\n",
    "\n",
    "* **Inner:** keep **only** matching keys (intersection).\n",
    "* **Outer:** keeps **all** keys in both DataFrames (union).\n",
    "* **Left:** keep all keys in the left DataFrame, whether or not they are in the right DataFrame.\n",
    "* **Right:** keep all keys in the right DataFrame, whether or not they are in the left DataFrame.\n",
    "\n",
    "<center><img src='imgs/image_1.png' width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples of join types\n",
    "\n",
    "- To specify which type of join we want to perform, we use the `how` argument (the default is `how='inner'`).\n",
    "- The left DataFrame is the DataFrame that **preceeds** `.merge`, and the right DataFrame is the argument to `merge`.\n",
    "- Alternatively, you can use the `pd.merge` **function**, in which the first argument is the left DataFrame and the second argument is the right DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an outer join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge is also a pandas function\n",
    "pd.merge(temps, countries, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `NaN`s in the rows for `'Rome'` and `'Shanghai'`.\n",
    "\n",
    "Also note that an outer join is what `pd.concat` does by default, when there are no duplicated keys in either DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([temps.set_index('City'), countries.set_index('City')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try left and right joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a left join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about a right join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `a.merge(b, how='left')` is the same as `b.merge(a, how='right')`. The only difference is the order of the columns in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.merge(temps, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specifying join keys\n",
    "\n",
    "- `pandas` defaults to using the shared column(s) as join keys.\n",
    "- If there are multiple shared column names and you only want to join on one of them, **or** if there are no shared column names, then you will need to specify which columns to join on.\n",
    "- Two solutions:\n",
    "    1.  Use the `on` argument if the desired column(s) have the same names in both DataFrames.\n",
    "    2. Use the `left_on` or `left_index` argument AND the `right_on` or `right_index` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = pd.DataFrame({\n",
    "    'PID': ['A15253545', 'A10348245', 'A13349069', 'A18485824', 'A10094857'],\n",
    "    'Student': ['Billy', 'Sally', 'Annie', 'Larry', 'Johnny'],\n",
    "    'Final': [88, 64, 91, 45, 89]\n",
    "})\n",
    "\n",
    "overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need to tell `pandas` to look in the `'Name'` column of `exams` and `'Student'` column of `overall`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall, left_on='Name', right_on='Student')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are shared column names in the two DataFrames you are merging **that you are not using as join keys**, by default `'_x'` and `'_y'` are appended to their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall, left_on='Name', right_on='Student', suffixes=('_Exam', '_Overall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the desired join key is in the index, assign `left_index` or `right_index` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_by_student = overall.set_index('Student')\n",
    "overall_by_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall_by_student, left_on='Name', right_index=True, suffixes=('_Exam', '_Overall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Many-to-one & many-to-many joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One-to-one joins\n",
    "\n",
    "- So far in this lecture, the joins we have worked with are called **one-to-one** joins.\n",
    "- Neither the left DataFrame nor the right DataFrame contained any duplicates in the join key.\n",
    "- What if there are duplicated join keys, in one or both of the DataFrames we are merging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Many-to-one joins\n",
    "\n",
    "- Many-to-one joins are joins where **one** of the DataFrames contains duplicate values in the join key. \n",
    "- The resulting DataFrame will preserve those duplicate entries as appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs = pd.DataFrame(\n",
    "[['Brad', 'UCB', 8],\n",
    " ['Janine', 'UCSD', 7],\n",
    " ['Marina', 'UIC', 6],\n",
    " ['Justin', 'OSU', 4],\n",
    " ['Aaron', 'UCB', 4],\n",
    " ['Soohyun', 'UCSD', 1],\n",
    " ['Suraj', 'UCB', 1]],\n",
    "    columns=['Name', 'School', 'Years']\n",
    ")\n",
    "\n",
    "profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools = pd.DataFrame({\n",
    "    'Abr': ['UCSD', 'UCLA', 'UCB', 'UIC'],\n",
    "    'Full': ['University of California, San Diego', 'University of California, Los Angeles', 'University of California, Berkeley', 'University of Illinois Chicago']\n",
    "})\n",
    "\n",
    "schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when merging `profs` and `schools`, the information from `schools` is duplicated (`'University of California, San Diego'` appears twice and `'University of California, Berkeley'` appears three times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs.merge(schools, left_on='School', right_on='Abr', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Many-to-many joins\n",
    "\n",
    "Many-to-many joins are joins where both DataFrames have duplicate values in the join key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs = pd.DataFrame({\n",
    "    'uni': ['UCSD', 'UCSD', 'UCSD', 'UCB', 'OSU', 'OSU'],\n",
    "    'dept': ['Math', 'HDSI', 'COGS', 'CS', 'Math', 'CS'],\n",
    "    'grad_students': [205, 54, 281, 439, 304, 193]\n",
    "})\n",
    "\n",
    "programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the following cell, try predicting the number of rows in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs.merge(programs, left_on='School', right_on='uni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `merge` stitched together every UCSD row in `profs` with every UCSD row in `programs`. \n",
    "- Since there were 2 UCSD rows in `profs` and 3 in `programs`, there are $2 \\cdot 3 = 6$ UCSD rows in the output. The same applies for all other schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: SDPD vehicle stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: accessing file names programmatically\n",
    "\n",
    "- At times, you'll need to load in all of the files in a given folder.\n",
    "- `os.listdir(dirname)` returns a **list** of the names of the files in the folder `dirname`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes, you'll want to extract file names that follow a specific pattern. The `pathlib` library allows you to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "file_list = list(pathlib.Path().glob('data/stops*.csv')) # glob allows for pattern matching\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can accomplish something similar in the command-line.\n",
    "- Place a `!` in front of a command in a Jupyter Notebook cell to run it on the command-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/stops*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [pd.read_csv(file) for file in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in list_of_dfs:\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to concatenate these two DataFrames **vertically**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pd.concat(list_of_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Investigating races\n",
    "\n",
    "Right now, `'subject_race'` is stored as a single character. What does `'I'` mean? `'H'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops['subject_race'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we have access to another dataset that describes each of the race codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = pd.read_csv('data/race_codes.csv')\n",
    "races"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's join the distribution of races with the DataFrame of race codes.\n",
    "\n",
    "**Question:** Is this a one-to-one join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_percentages = stops['subject_race'].value_counts(normalize=True).rename('Proportion').to_frame()\n",
    "race_percentages.merge(races, left_index=True, right_on='Race Code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **level of granularity** of the races in our data right now seems inconsistent. For instance, `'WHITE'` and `'BLACK'` are much more broad than `'FILIPINO'`, `'JAPANESE'`, and `'GUAMANIAN'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adjusting granularity\n",
    "\n",
    "Let's try and adjust our race data so that we have a consistent level of granularity. Here's what we want to create:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Race Code</th>\n",
    "      <th>Description</th>\n",
    "      <th>Race_Category</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>A</td>\n",
    "      <td>OTHER ASIAN</td>\n",
    "      <td>Asian</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>B</td>\n",
    "      <td>BLACK</td>\n",
    "      <td>Black</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>C</td>\n",
    "      <td>CHINESE</td>\n",
    "      <td>Asian</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>D</td>\n",
    "      <td>CAMBODIAN</td>\n",
    "      <td>Asian</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>F</td>\n",
    "      <td>FILIPINO</td>\n",
    "      <td>Asian</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "We can do this by manually defining a mapping between race codes and desired categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dict = {'A':'Asian',\n",
    "             'B':'Black',\n",
    "             'C':'Asian',\n",
    "             'D':'Asian',\n",
    "             'F':'Asian',\n",
    "             'G':'Asian',\n",
    "             'H':'Hispanic',\n",
    "             'I':'Native American',\n",
    "             'J':'Asian',\n",
    "             'K':'Asian',\n",
    "             'L':'Asian',\n",
    "             'O':'Other',\n",
    "             'P':'Asian',\n",
    "             'S':'Asian',\n",
    "             'U':'Hawaiian',\n",
    "             'V':'Asian',\n",
    "             'W':'White',\n",
    "             'Z':'Asian'\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to replace all of the `'Race Code'`s in `races` with the above categories:\n",
    "- Use the Series `replace` method.\n",
    "- Convert the above mapping to a DataFrame and join it with `races`.\n",
    "\n",
    "Joining requires sorting, where as replacing does not. Let's go with the first option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races['Race_Category'] = races['Race Code'].replace(race_dict)\n",
    "races"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to join `stops` with `races`. An important question is, what type of join should we use (inner, outer, left, right)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops['subject_race'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we don't discard the individuals whose races we don't have, we will use a **left join**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_merged = stops.merge(races, left_on='subject_race', right_on='Race Code', how='left')\n",
    "stops_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute a more meaningful distribution of races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stops_merged['Race_Category'].value_counts(normalize=True)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.plot(kind='bar', figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a bit more helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aside: Working with time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Time series ‚Äì why now?\n",
    "\n",
    "- Data is often partitioned by time. For instance, there may be one `.csv` file per day for 1 year.\n",
    "- To combine the datasets, we will need to load in the files as DataFrames and `pd.concat` the DataFrames together.\n",
    "- Note: \"time series\" is a general term and is not related to Series in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Datetime types\n",
    "\n",
    "When working with time data, you will see two different kinds of \"times\":\n",
    "\n",
    "* **Datetimes** reference particular moments in time (e.g. November 26th, 1998 at 8:26AM).\n",
    "    - Could just be a date, e.g. September 15, 2014.\n",
    "    - Could just be a time, e.g. 4:45 AM.\n",
    "    - Datetimes typically don't keep track of timezones.\n",
    "* **Timedeltas**, or durations, reference an exact length of time (e.g. a duration of 3 hours)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `datetime` module\n",
    "\n",
    "Python has an in-built `datetime` module, which contains `datetime` and `timedelta` types. These are much more convenient to deal with than strings that contain times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now() + datetime.timedelta(days=3, hours=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, Unix timestamps count the number of seconds since January 1st, 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now().timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Times in `pandas`\n",
    "\n",
    "- `pd.Timestamp` is the `pandas` equivalent of `datetime`.\n",
    "- `pd.to_datetime` converts strings to `pd.Timestamp` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(year=1998, month=11, day=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_start = pd.to_datetime('June 4th, 2022, 11:30AM')\n",
    "final_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish = pd.to_datetime('June 4th, 2022, 2:30PM')\n",
    "final_finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps have time-related attributes, e.g. `dayofweek`, `hour`, `min`, `sec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_finish.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtracting timestamps yields `pd.Timedelta` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish - final_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Timestamps in DataFrames\n",
    "\n",
    "- If we create a Series of datetimes with `pd.to_datetime`, `pandas` stores them as yet *another* type:\n",
    "`np.datetime64`.\n",
    "    - These are similar to `pd.Timestamp`, but optimized for memory and speed efficiency.\n",
    "- If we access a single time, we get a `pd.Timestamp` back.\n",
    "- See [the documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times = pd.DataFrame({'finish': pd.to_datetime(['Sun, Jan 01, 1989', \n",
    "                                                '2022-04-15T11:00', \n",
    "                                                '1/1/1970'])})\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times.sort_values('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Exam speeds\n",
    "\n",
    "Below, we have the Final Exam starting and ending times for two sections of a course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_A = pd.DataFrame({\n",
    "    'Name': ['Annie', 'Billy', 'Sally', 'Tommy'],\n",
    "    'start_exam': ['15:00', '15:02', '15:01', '15:00'],\n",
    "    'finish_exam': ['16:00', '17:58', '17:05', '16:55']\n",
    "})\n",
    "\n",
    "times_B = pd.DataFrame({\n",
    "    'Name': ['Junior', 'Rex', 'Flash'],\n",
    "    'start_exam': ['18:00', '18:06', '19:07'],\n",
    "    'finish_exam': ['20:00', '20:50', '20:59']\n",
    "})\n",
    "\n",
    "display(times_A)\n",
    "display(times_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Who finished the exam the fastest amongst all students in the course?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Approach:\n",
    "1. Concatenate the two DataFrames.\n",
    "2. Convert the time columns to `pd.Timestamp`.\n",
    "3. Find the difference between `'finish_exam'` and `'start_exam'`.\n",
    "4. Sort.\n",
    "5. Pick the fastest exam taker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "both_versions = pd.concat([times_A, times_B])\n",
    "both_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "both_versions = both_versions.assign(\n",
    "    start_exam=pd.to_datetime(both_versions['start_exam']),\n",
    "    finish_exam=pd.to_datetime(both_versions['finish_exam'])\n",
    ")\n",
    "\n",
    "both_versions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "both_versions = both_versions.assign(\n",
    "    elapsed=both_versions['finish_exam'] - both_versions['start_exam']\n",
    ")\n",
    "\n",
    "both_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps 4 and 5\n",
    "both_versions.sort_values('elapsed').iloc[0].loc['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- `pd.concat` \"stitches\" two or more DataFrames together, either vertically or horizontally.\n",
    "    - Vertically: looks at column names. Horizontally: looks at row indexes.\n",
    "- The `merge` DataFrame method **joins** two DataFrames together based on a shared column, called a join key. There are four types of joins:\n",
    "    - Inner join: keeps the **intersection** of the join keys.\n",
    "    - Outer join: keeps the **union** of the join keys.\n",
    "    - Left/right joins: keeps all of the join keys in the left/right DataFrame.\n",
    "    - In outer/left/right joins, all missing fields are filled with `NaN`s.\n",
    "- Timestamps in `pandas` are stored using `pd.Timestamp` and `pd.Timedelta` objects.\n",
    "- **Next time:** Permutation testing!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
