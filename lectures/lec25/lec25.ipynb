{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 25 ‚Äì Decision Trees, Grid Search, and Multicollinearity\n",
    "\n",
    "## DSC 80, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Project 4 is due **tomorrow at 11:59PM**.\n",
    "    - IMPORTANT: See [this post](https://campuswire.com/c/G325FA25B/feed/1511) for more public tests for Question 5.\n",
    "- Lab 9 is due on **Tuesday, May 31st at 11:59PM** (note the later deadline).\n",
    "- Discussion 8 (the final discussion of the quarter) is tonight.\n",
    "- Project 3 grades are released, and the Grade Report has been updated!\n",
    "- Project 5 will be released on Friday.\n",
    "- The Final Exam is on **Saturday, June 4th from 11:30AM-2:30PM in-person**!\n",
    "    - You may bring 2 two-sided cheat sheets.\n",
    "    - More details soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "- Decision trees üå≤ and grid searching.\n",
    "- Multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap: Generalization\n",
    "\n",
    "1. Split the data into two sets: <span style='color: blue'><b>training</b></span> and <span style='color: orange'><b>test</b></span>.\n",
    "\n",
    "2. Use only the <span style='color: blue'><b>training</b></span> data when designing, training, and tuning the model.\n",
    "    - Use <span style='color: green'><b>cross-validation</b></span> to choose hyperparameters and estimate the model's ability to generalize.\n",
    "    - Do not ‚ùå look at the <span style='color: orange'><b>test</b></span> data in this step!\n",
    "    \n",
    "3. Commit to your final model and train it using the entire <span style='color: blue'><b>training</b></span> set.\n",
    "\n",
    "4. Test the data using the <span style='color: orange'><b>test</b></span> data. If the performance (e.g. RMSE) is not acceptable, return to step 2.\n",
    "\n",
    "5. Finally, train on **all available data** and ship the model to production! üõ≥\n",
    "\n",
    "üö® This is the process you should **always** use! üö® "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question ü§î\n",
    "\n",
    "We won't answer this question in class, but **it's a good exam-prep question!**\n",
    "\n",
    "- Suppose you have a training dataset with 1000 rows.\n",
    "- You want to decide between 20 hyperparameters for a particular model.\n",
    "- To do so, you perform 10-fold cross-validation.\n",
    "- **How many times is the first row in the training dataset (`X.iloc[0]`) used for training a model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Decision trees üå≤ and grid searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/taxonomy.png' width=50%></center>\n",
    "\n",
    "Decision trees can be used for both regression and classification. We will start by discussing their use in **classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration, we'll use `'Glucose'` and `'BMI'` to predict whether or not a patient has diabetes (the response variable is in the `'Outcome'` column)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's build a decision tree and interpret the results. But first, a train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diabetes[['Glucose', 'BMI']], \n",
    "                                                    diabetes['Outcome'],\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant class is `DecisionTreeClassifier`, from `sklearn.tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we `fit` it the same way we `fit` earlier estimators.\n",
    "\n",
    "_You may wonder what `max_depth=2` does ‚Äì more on this soon!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing decision trees\n",
    "\n",
    "Our fit decision tree is like a \"flowchart\", made up of a series of questions.\n",
    "\n",
    "<span style='color: orange'><b>Class 0 (orange) is \"no diabetes\"</b></span>; <span style='color: blue'><b>Class 1 (blue) is \"diabetes\"</b></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_tree(dt, feature_names=X_train.columns, class_names=['no', 'yes'], \n",
    "               filled=True, rounded=True, fontsize=15, impurity=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To **classify a new data point**, we start at the top and answer the first question (i.e. \"Glucose <= 129.5\").\n",
    "- If the answer is \"Yes\", we move to the left branch, otherwise we move to the right branch.\n",
    "- We repeat this process until we end up at a leaf node, at which point we predict the most common class in that node.\n",
    "    - Note that each node has a `value` attribute, which describes the number of **training** individuals of each class that fell in that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the left node at depth 2 has a `value` of [304, 78]\n",
    "y_train.loc[X_train[X_train['Glucose'] <= 129.5].index].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating classifiers\n",
    "\n",
    "The most common evaluation metric in classification is **accuracy**:\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\text{# data points classified correctly}}{\\text{# data points}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dt.predict(X_train) == y_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `score` method of a classifier computes accuracy by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy ‚Äì same number as above\n",
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing accuracy\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some questions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How did `sklearn` decide what questions to ask?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Can we ask more questions (i.e. build a **deeper** tree)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training a decision tree\n",
    "\n",
    "When we ask a question, we are effectively **splitting** a node into two children ‚Äì the \"yes\" child and the \"no\" child."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Suppose the distribution within a node looks like this (colors represent classes):\n",
    "\n",
    "<center>üîµüîµüîµüîµüîµüîµüîµüî¥üî¥üî¥</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Question A **splits** the node like this:\n",
    "- \"Yes\": üîµüîµüîµüî¥üî¥\n",
    "- \"No\": üîµüîµüîµüîµüî¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Question B **splits** the node like this:\n",
    "- \"Yes\": üîµüîµüîµüîµüîµüîµ\n",
    "- \"No\": üîµüî¥üî¥üî¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Which question is \"better\"?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Question B, because there is \"less uncertainty\" in the resulting nodes after splitting by Question B than there is after splitting by Question A. There are two common techniques for quantifying \"uncertainty\":\n",
    "- Gini impurity (the default in `sklearn`).\n",
    "- Entropy (from information theory).\n",
    "\n",
    "Not the focus of our course, but read more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tree depth\n",
    "\n",
    "Decision trees are trained by **recursively** picking the best split until:\n",
    "- all \"leaf nodes\" only contain training examples from a single class (good), or\n",
    "- it is impossible to split leaf nodes any further (not good).\n",
    "\n",
    "By default, there is no \"maximum depth\" for a decision tree. As such, without restriction, decision trees tend to be very deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_no_max = DecisionTreeClassifier()\n",
    "dt_no_max.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree fit on our training data has a depth of around 20! (It is so deep that `tree.plot_tree` errors when trying to plot it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_no_max.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, this tree seems \"better\" than our tree of depth 2, since its training accuracy is much much higher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_no_max.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth 2 tree\n",
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But recall, we truly care about **test set performance**, and this decision tree has **worse accuracy on the test set than our depth 2 tree**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_no_max.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth 2 tree\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision trees and overfitting\n",
    "\n",
    "- Decision trees have a tendency to overfit. **Why is that?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Unlike linear classification techniques (like logistic regression or SVMs), **decision trees are non-linear**.\n",
    "    - They are also \"non-parametric\" ‚Äì there are no $w^*$s to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- While being trained, decision trees ask enough questions to effectively **memorize** the correct response values in the training set. However, the relationships they learn are often overfit to the noise in the training set, and don't generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Fact:** A decision tree whose depth is not restricted will achieve 100% accuracy on any training set, as long as there are no \"overlapping values\" in the training set.\n",
    "    - Two values overlap when they have the same features $x$ but different response values $y$ (e.g. if two patients have the same glucose levels and BMI, but one has diabetes and one doesn't)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One solution:** Make the decision tree \"less complex\" by limiting the maximum depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since `sklearn.tree`'s `plot_tree` can't visualize extremely large decision trees, let's create and visualize some smaller decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = {}\n",
    "for d in [2, 4, 8]:\n",
    "    trees[d] = DecisionTreeClassifier(max_depth=d, random_state=1)\n",
    "    trees[d].fit(X_train, y_train)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5), dpi=100)\n",
    "    plot_tree(trees[d], feature_names=X_train.columns, class_names=['no', 'yes'], \n",
    "               filled=True, rounded=True, impurity=False)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As tree depth increases, complexity increases.\n",
    "\n",
    "**Question:** What is the right maximum depth to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hyperparameters for decision trees\n",
    "\n",
    "- `max_depth` is a hyperparameter for `DecisionTreeClassifier`.\n",
    "- There are many more hyperparameters we can tweak; look at [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for examples.\n",
    "    - `min_samples_split`: The minimum number of samples required to split an internal node.\n",
    "    - `criterion`: The function to measure the quality of a split (`'gini'` or `'entropy'`).\n",
    "- **We need an efficient technique for trying different combinations of hyperparameters!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid search\n",
    "\n",
    "`GridSearchCV` takes in:\n",
    "- an **un-`fit`** instance of an estimator, and\n",
    "- a **dictionary** of hyperparameter values to try,\n",
    "\n",
    "and performs $k$-fold cross-validation to find the **combination of hyperparameters with the best average validation performance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following dictionary contains the values we're considering for each hyperparameter. (We're using `GridSearchCV` with 3 hyperparameters, but we could it with even just a single hyperparameter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': [2, 3, 4, 5, 7, 10, 13, 15, 18, None], \n",
    "    'min_samples_split': [2, 3, 5, 7, 10, 15, 20],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are 140 **combinations** of hyperparameters we need to try. We need to find the **best combination** of hyperparameters, not the best value for each hyperparameter individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hyperparameters['max_depth']) * len(hyperparameters['min_samples_split']) * len(hyperparameters['criterion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` needs to be instantiated and `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = GridSearchCV(DecisionTreeClassifier(), hyperparameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After being `fit`, the `best_params_` attribute provides us with the best combination of hyperparameters to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the intermediate results ‚Äì validation accuracies for each fold, mean validation accuaries, etc. ‚Äì are stored in the `cv_results_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searcher.cv_results_['mean_test_score'] # array of length 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows correspond to folds, columns correspond to hyperparameter combinations\n",
    "pd.DataFrame(np.vstack([searcher.cv_results_[f'split{i}_test_score'] for i in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above DataFrame tells us that 5 * 140 = 700 models were trained in total!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How is the following line of code making predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.predict(X_train)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model's testing accuracy is shown below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key takeaways\n",
    "\n",
    "- Decision trees are trained by finding the best questions to ask using the features in the training data. A good question is one that isolates classes as much as possible.\n",
    "- Decision trees have a tendency to overfit to training data. One way to mitigate this is by restricting the maximum depth of the tree.\n",
    "- To efficiently find hyperparameters through cross-validation, use `GridSearchCV`.\n",
    "    - Specify which values to try for each hyperparameter, and `GridSearchCV` will try all **unique combinations of hyperparameters** and return the combination with the best average validation performance.\n",
    "    - `GridSearchCV` is not the only solution ‚Äì see [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) if you're curious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivating example\n",
    "\n",
    "Suppose we fit a simple linear regression model that uses **height in inches** to predict **weight in pounds**.\n",
    "\n",
    "$$\\text{predicted weight} = w_0 + w_1 \\cdot \\text{height (inches)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.read_csv('data/SOCR-HeightWeight.csv').drop('Index', axis=1)\n",
    "people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(people[['Height(Inches)']], \n",
    "                                                            people['Weight(Pounds)'], \n",
    "                                                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_one_feat = LinearRegression()\n",
    "lr_one_feat.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_0^*$ and $w_1^*$ are shown below, along with the model's **testing** RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_one_feat.intercept_, lr_one_feat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_one_feat = mean_squared_error(y_test_1, \n",
    "                                   lr_one_feat.predict(X_test_1), \n",
    "                                   squared=False)\n",
    "rmse_one_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, suppose we fit another regression model, that uses **height in inches** AND **height in centimeters** to predict weight.\n",
    "\n",
    "$$\\text{predicted weight} = w_0 + w_1 \\cdot \\text{height (inches)} + w_2 \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people['Height(cm)'] = people['Height(Inches)'] * 2.54 # 1 inch = 2.54 cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(people[['Height(Inches)', 'Height(cm)']], \n",
    "                                                            people['Weight(Pounds)'], \n",
    "                                                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_two_feat = LinearRegression()\n",
    "lr_two_feat.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are $w_0^*$, $w_1^*$, $w_2^*$, and the model's testing RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_two_feat.intercept_, lr_two_feat.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_two_feat = mean_squared_error(y_test_2, \n",
    "                                   lr_two_feat.predict(X_test_2), \n",
    "                                   squared=False)\n",
    "rmse_two_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Observation:** The intercept is the same as before (roughly -81.17), as is the testing RMSE. However, the coefficients on `'Height(Inches)'` and `'Height(cm)'` are massive in size!\n",
    "\n",
    "What's going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Redundant features\n",
    "\n",
    "Let's use simpler numbers for illustration. Suppose in the first model, $w_0^* = -80$ and $w_1^* = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{predicted weight} = -80 + 3 \\cdot \\text{height (inches)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the second model, we have:\n",
    "\n",
    "$$\\begin{align*}\\text{predicted weight} &= w_0^* + w_1^* \\cdot \\text{height (inches)} + w_2^* \\cdot \\text{height (cm)} \\\\ &= w_0^* + w_1^* \\cdot \\text{height (inches)} + w_2^* \\cdot \\big( 2.54^* \\cdot \\text{height (inches)} \\big) \\\\ &= w_0^* + \\left(w_1^* + 2.54 \\cdot w_2^* \\right) \\cdot \\text{height (inches)} \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the first model, we already found the \"best\" intercept and slope in a linear model that uses height in inches to predict weight ($-80$ and $3$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, as long as $w_1^* + 2.54 \\cdot w_2^* = 3$ in the second model, the second model's training predictions will be the same as the first, and hence they will also minimize RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Infinitely many parameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Issue:** There are an infinite number of $w_1^*$ and $w_2^*$ that satisfy $w_1^* + 2.54 \\cdot w_2^* = 3$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{predicted weight} = -80 - 10 \\cdot \\text{height (inches)} + \\frac{13}{2.54} \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{predicted weight} = -80 + 10 \\cdot \\text{height (inches)} - \\frac{7}{2.54} \\cdot \\text{height (cm)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Both prediction rules look very different, but actually make the same predictions on the training set.\n",
    "- `lr.coef_` could return either set of coefficients, or any other of the infinitely many options. \n",
    "- But neither set of coefficients is **has any meaning!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-80 - 10 * people.iloc[:, 0] + (13 / 2.54) * people.iloc[:, 2]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-80 + 10 * people.iloc[:, 0] - (7 / 2.54) * people.iloc[:, 2]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multicollinearity\n",
    "\n",
    "- Multicollinearity occurs when features in a regression model are **highly correlated** with one another.\n",
    "    - In other words, multicollinearity occurs when **a feature can be predicted using a linear combination of other features, fairly accurately**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When multicollinearity is present in the features, the **coefficients in the model** are uninterpretable ‚Äì they have no meaning.\n",
    "    - A \"slope\" represents \"the rate of change of $y$ with respect to a feature\", when all other features are held constant ‚Äì but if there's multicollinearity, you can't hold other features constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Note: Multicollinearity doesn't impact a model's predictions!**\n",
    "    - It doesn't impact a model's ability to generalize to unseen data.\n",
    "    - If features are multicollinear in the training data, they will probably be multicollinear in the test data too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solutions:**\n",
    "    - Manually remove highly correlated features.\n",
    "    - Use a dimensionality reduction technique (such as PCA) to automatically reduce dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One-hot encoding and multicollinearity\n",
    "\n",
    "When we one-hot encode categorical features, we create several **redundant** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips_features = tips.drop('tip', axis=1)\n",
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: You can use `pd.get_dummies` in EDA, but **don't** use it for modeling (instead, use `OneHotEncoder`, which works with `Pipeline`s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(tips_features)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that under the hood, `LinearRegression()` creates a **design matrix** that has a column of all ones (for the intercept term). Let's add that column above for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['all_ones'] = 1\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, many of the above columns **can be written as linear combinations of other columns**!\n",
    "- We don't need `'sex_Male'` ‚Äì its value is just `'all_ones'` - `'sex_Female'`.\n",
    "- We don't need `'smoker_Yes'` ‚Äì its value is just `'all_ones'` - `'smoker_No'`.\n",
    "- We don't need `'time_Lunch'` ‚Äì its value is just `'all_ones'` - `'time_Dinner'`.\n",
    "- We don't need `'day_Thur'` ‚Äì its value is just `'all_ones'` - (`'day_Fri'` + `'day_Sat'` + `'day_Sun'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we get rid of the four redundant columns above, the **rank** of our design matrix ‚Äì that is, the number of linearly independent columns it has ‚Äì does not change (and so the \"predictive power\" of our features don't change either)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(X.drop(columns=['sex_Male', 'smoker_Yes', 'time_Lunch', 'day_Thur']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, without the redundant columns, there is only a single unique set of optimal parameters $w^*$, and the multicollinearity is no more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Aside:** Most one-hot encoding techniques (including `OneHotEncoder`) have an in-built `drop` argument, which allow you to specify that you'd like to drop **one column per categorical feature**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(tips_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop='first')\n",
    "ohe.fit_transform(tips_features[['sex', 'smoker', 'day', 'time']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above array only has $(2-1) + (2-1) + (4-1) + (2-1) = 6$ columns, rather than $2 + 2 + 4 + 2 = 10$, since we dropped 1 per categorical column in `tips_features`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key takeaways\n",
    "\n",
    "- Multicollinearity is present in a linear model when one feature can be accurately predicted using one or more other features.\n",
    "    - In other words, it is present when a feature is **redundant**.\n",
    "- Multicollinearity doesn't pose an issue for prediction; it doesn't hinder a model's ability to generalize. Instead, it renders the **coefficients** of a linear model meaningless.\n",
    "- Multicollinearity is present when performing one-hot encoding; a solution is to drop **one one-hot-encoded column for each original categorical feature**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- See the individual sections for more specific \"key takeaways\".\n",
    "- **Next time:** \n",
    "    - Using text features in a predictive model.\n",
    "    - Metrics for measuring the performance of classifiers other than accuracy."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
